# Lab1_CNN

Questo progetto implementa una rete convoluzionale profonda (CNN) per compiti di classificazione di immagini, basata sull'architettura ResNet-18 e sulla tecnica di Class Activation Maps (CAM) per l'interpretabilità del modello. L'obiettivo è sfruttare un modello pre-addestrato ResNet-18 per estrarre caratteristiche efficaci e utilizzare CAM per visualizzare le aree di interesse del modello durante le predizioni.

## Architettura

- **ResNet-18**: Il modello utilizza l'architettura ResNet-18, introdotta da He et al. (2016), che ha rivoluzionato il training di reti molto profonde tramite blocchi residuali. ResNet-18 è composta da 17 layer convoluzionali, un max pooling layer e uno strato fully connected. La caratteristica chiave è l'uso di connessioni skip (residual connections) che mitigano il problema del gradiente che svanisce, consentendo un training più stabile e profondo [He et al., 2016][web:3].

- **Class Activation Maps (CAM)**: La tecnica CAM consente di localizzare le regioni dell'immagine che contribuiscono maggiormente alla decisione del modello, migliorando l'interpretabilità. CAM calcola una mappa di attivazione pesata delle feature maps estratte dall'ultimo layer convoluzionale tramite i pesi del layer fully connected. Introdotto da Zhou et al. (2015), CAM è fondamentale per la visualizzazione delle regioni discriminanti del modello [Zhou et al., 2015; Lee et al., 2021][web:6][web:8].

## Dataset

Il modello è addestrato e testato su dataset di immagini comunemente usati per classificazione:

- **MNIST**: Dataset di immagini in scala di grigi di cifre scritte a mano, con 60.000 immagini di training e 10.000 di test, di dimensioni 28x28 pixel. È uno standard per il benchmarking di modelli di classificazione di immagini [web:16].

- **CIFAR-10**: Dataset di 60.000 immagini a colori di dimensioni 32x32 pixel, suddivise in 10 classi di oggetti (ad esempio aerei, automobili, uccelli, gatti, cani, ecc.), con 50.000 immagini per il training e 10.000 per il testing. È ampiamente usato per la ricerca in visione artificiale [web:11][web:13].

- **Imaginette**: Un sottoinsieme di ImageNet ottimizzato per la classificazione veloce, con un numero limitato di classi e immagini. È usato come benchmark leggero per addestrare e testare modelli di classificazione.

## Installazione

1. Clonare il repository:
git clone https://github.com/lucrezio001/Deep-Leaning-Application-Luca-Capece.git
cd Deep-Leaning-Application-Luca-Capece/Lab1_CNN


2. Installare le dipendenze Python:
pip install -r requirements.txt


## Uso

- Il training si basa su ResNet-18 pre-addestrato su ImageNet, con possibilità di fine-tuning sui dataset MNIST, CIFAR-10 o Imaginette.
- Per eseguire il training o la valutazione, utilizzare gli script Python presenti nella cartella.
- CAM è integrato per generare mappe di attivazione visualizzabili per ogni immagine classificata, per migliorare l'interpretabilità del modello.

## Riferimenti

- K. He, X. Zhang, S. Ren, and J. Sun, "Deep Residual Learning for Image Recognition," in *Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)*, 2016. [DOI PDF](https://arxiv.org/abs/1512.03385) [web:3]

- B. Zhou, A. Khosla, A. Lapedriza, A. Oliva, and A. Torralba, "Learning Deep Features for Discriminative Localization," arXiv preprint arXiv:1512.04150, 2015. [arXiv PDF](https://arxiv.org/abs/1512.04150) [web:8]

- H. Lee et al., "Relevance-CAM: Your Model Already Knows Where To Look," in *CVPR 2021*, 2021. [PDF](https://openaccess.thecvf.com/content/CVPR2021/papers/Lee_Relevance-CAM_Your_Model_Already_Knows_Where_To_Look_CVPR_2021_paper.pdf) [web:6]

